# 大模型基础

# 发展

在⼤规模数据上**自监督训练**，经**微调或提示**后适配各类任务

**过去：**为每个任务训练独立的模型

**过去不久：**中⼼节点完成预训练，用户在此基础上面向任务微调

**现在：**提示学习 上下文学习、思维链提示；轻量化微调

# 架构

**大规模语言模型：**通常指参数量超过 10B 的模型

1. 编码器：BERT、ALBERT
2. 解码器：GPT、Llama
3. 编码器-解码器：T5、BART

特别对于GPT系列

- **GPT-1：**单向自回归建模 + 有监督微调
- **GPT-2：**单向自回归建模 + 更多的数据、更⼤的模型 + 零样本学习
- **GPT-3：**继续扩充数据和模型规模 + 上下⽂提示学习
- **GPT-3.5/ChatGPT：**指令微调 +⼈类反馈 + 对话优化

# 微调

## 指令微调

通过**高质量指令数据**（告诉模型执行什么任务）对模型进行微调

- 帮助模型理解**任务特征**，⼤幅提升在各个任务上的性能表现
- 改善提示学习的**稳定性**，让模型输出文本**更为可控**

方式

- **借助现有的数据集**：通过人为添加指定当前任务类型的提示作为输入的前缀（指令），在多类型数据集上进⾏微调
- **基于人类演示的有监督微调**：基于人类根据提示（指令）撰写的高质量回答，模型据此来进⾏有监督微调

## **LoRA微调**

### 基于低秩的轻量化微调方法

核心思想：参数优化量可以是低秩的，映射到低维空间下也能保持性能

实现手段：对模型参数的优化量进行低秩近似，以残差的方式更新参数

**全参数微调 = 冻结的预训练权重 + 微调过程中产生的权重更新量**

具体公式推导可见论文

# **涌现能力与幻觉问题**

## **幻觉问题**

定义：模型生成的文本不遵循原文（Faithfulness）或不符合事实（Factualness）

原因：

1. 指令描述和约束不够，缺乏足够的输⼊，模型仅能根据自己的知识进行猜测
2. 未见过、不认识的知识，模型通过猜测和瞎编回答
3. 模型接收了误导信息或基于错误的推测进行作答

## **面向大规模预训练模型的知识更新手段**

1. **提示学习**
    1. **上下文提示→上下文检索增强**
    2. **思维链提示：**引导模型生成**中间思维步骤**，进而推导答案

## **涌现**

在数学推理、常识推理和逻辑推理复杂任务上的性能超越常规微调模型，模型参数大于一定量，突然出现（提升）的能力